## Install the required packages
## pip install -qU elasticsearch openai

import os
from elasticsearch import Elasticsearch
from openai import OpenAI


es_client = Elasticsearch(
    "https://6a5dbb110e064dbf92b651d18e65f96c.us-east-1.aws.found.io:443",
    api_key=os.environ["ES_API_KEY"]
)
      

openai_client = OpenAI(
    api_key=os.environ["OPENAI_API_KEY"],
)

index_source_fields = {
    "search-moodle-apnews": [
        "body_content"
    ],
    "search-moodle-training-website": [
        "body_content"
    ],
    "search-moodle-website": [
        "body_content"
    ]
}

def get_elasticsearch_results():
    es_query = {
        "retriever": {
            "rrf": {
                "retrievers": [
                    {
                        "standard": {
                            "query": {
                                "multi_match": {
                                    "query": query,
                                    "fields": [
                                        "body_content",
                                        "title"
                                    ]
                                }
                            }
                        }
                    },
                    {
                        "standard": {
                            "query": {
                                "multi_match": {
                                    "query": query,
                                    "fields": [
                                        "body_content",
                                        "title"
                                    ]
                                }
                            }
                        }
                    },
                    {
                        "standard": {
                            "query": {
                                "multi_match": {
                                    "query": query,
                                    "fields": [
                                        "body_content",
                                        "title"
                                    ]
                                }
                            }
                        }
                    }
                ]
            }
        },
        "size": 10
    }

    result = es_client.search(index="search-moodle-apnews,search-moodle-training-website,search-moodle-website", body=es_query)
    return result["hits"]["hits"]

def create_openai_prompt(results):
    context = ""
    for hit in results:
        inner_hit_path = f"{hit['_index']}.{index_source_fields.get(hit['_index'])[0]}"

        ## For semantic_text matches, we need to extract the text from the inner_hits
        if 'inner_hits' in hit and inner_hit_path in hit['inner_hits']:
            context += '\n --- \n'.join(inner_hit['_source']['text'] for inner_hit in hit['inner_hits'][inner_hit_path]['hits']['hits'])
        else:
            source_field = index_source_fields.get(hit["_index"])[0]
            hit_context = hit["_source"][source_field]
            context += f"{hit_context}\n"

    prompt = f"""
  Instructions:
  
  - You are an assistant for question-answering tasks about a moodle website that focuses on usa marines courses
We are an org that monitors how the troops are using these courses to make sure the app is being used effiecently to help the missions of the us marines. We want to know how our courses sync to the current goals and initiatives that the marines are doing. We want to do this so that our training syncs closely to these goals. 
This RAG data set is a set of internet news articles that may be interesting in helping us know what major focuses are happening in the marines and if our training might be affecting this news. Our goal is that our training helps our marines change their methods and these news articles see this
  - Answer questions truthfully and factually using only the context presented.
  - If you don't know the answer, just say that you don't know, don't make up an answer.
  - You must always cite the document where the answer was extracted using inline academic citation style [], using the position.
  - Use markdown format for code examples.
  - You are correct, factual, precise, and reliable.
  

  Context:
  {context}

  
  """

    return prompt

def generate_openai_completion(user_prompt, question):
    response = openai_client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": user_prompt},
            {"role": "user", "content": question},
        ]
    )

    return response.choices[0].message.content

if __name__ == "__main__":
    question = "my question"
    elasticsearch_results = get_elasticsearch_results()
    context_prompt = create_openai_prompt(elasticsearch_results)
    openai_completion = generate_openai_completion(context_prompt, question)
    print(openai_completion)